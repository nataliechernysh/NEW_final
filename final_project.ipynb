{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Q4slgeV0K9Mn",
        "j-fuPAzQbrPk",
        "OIWJ1iIKqYss",
        "D9-BB7OxyVbs"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nataliechernysh/NEW_final/blob/main/final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anvil-uplink"
      ],
      "metadata": {
        "id": "nqXZK_7SpqQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import anvil.server"
      ],
      "metadata": {
        "id": "8INLZQZaqdp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anvil.server.connect(\"server_AHXTHQI46MJWDJ2TMOGZI3X5-CONLHEZHSSEZPNDK\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y87HiN8Rqnih",
        "outputId": "517d367a-155d-4373-8f35-abc167636618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Disconnecting from previous connection first...\n",
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default Environment\" as SERVER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@anvil.server.callable #so it is available to call from our anvil \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "DjbTg08cq2sF",
        "outputId": "d1bd9e83-56fb-4493-c2ac-d7966cc6018e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-e058c1f3373d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Files\n"
      ],
      "metadata": {
        "id": "Q4slgeV0K9Mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import signal \n",
        "from matplotlib import pyplot as pyplot\n",
        "%matplotlib inline\n",
        "!pip install ipympl\n",
        "%matplotlib widget\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "aGqq05w3XBf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7961a0f-f550-4adb-e69a-ed36afd0d174"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipympl in /usr/local/lib/python3.10/dist-packages (0.9.3)\n",
            "Requirement already satisfied: ipython<9 in /usr/local/lib/python3.10/dist-packages (from ipympl) (7.34.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.10/dist-packages (from ipympl) (7.7.1)\n",
            "Requirement already satisfied: matplotlib<4,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from ipympl) (3.7.1)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.10/dist-packages (from ipympl) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipympl) (0.2.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from ipympl) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ipympl) (1.22.4)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (3.0.38)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (67.7.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (4.8.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (0.18.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (4.4.2)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (0.1.6)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<9->ipympl) (2.14.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.6.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (3.0.7)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipympl) (5.5.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (0.11.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (23.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4,>=3.4.0->ipympl) (3.0.9)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets<9,>=7.6.0->ipympl) (6.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<9->ipympl) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<9->ipympl) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<9->ipympl) (0.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib<4,>=3.4.0->ipympl) (1.16.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.4.8)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (21.3.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.8.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (5.3.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.1.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.17.1)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.8.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (3.3.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (21.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.1.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (6.0.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.7.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.5.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.2.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.4)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.2.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.9.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.7.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.19.3)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipympl) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files;\n",
        "df=files.upload();\n",
        "filename = list(df.keys ())[-1]\n",
        "ds= pd.ExcelFile(filename)\n",
        "sheetnames=ds.sheet_names\n",
        "datasheet=pd.read_excel(filename, sheet_name=0); \n",
        "!rm{filename}\n",
        "datasheet\n",
        "total_data_sheet = np.array(datasheet)"
      ],
      "metadata": {
        "id": "xMymvwZdaHCx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "de3ff78f-5b83-47e7-ddc3-be2837bfe394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1031d0c5-ae77-41ed-88b9-3249a6ffeebf\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1031d0c5-ae77-41ed-88b9-3249a6ffeebf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse into dictionaries"
      ],
      "metadata": {
        "id": "BNUzFr-MVGXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_data_sheet = np.array(datasheet)"
      ],
      "metadata": {
        "id": "oFvumYlwzQGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_accelerometer_data(total_data_sheet):\n",
        "  #accelerometer data contains two data points per frame\n",
        "  accelerometer_data = total_data_sheet[50626:54000,2:50]\n",
        "  #print(accelerometer_data)\n",
        "  temp_array = np.zeros(shape=(np.shape(accelerometer_data)[0]//2, 48))\n",
        "\n",
        "  #goes through all of the accelerometer data and finds the average of each of\n",
        "  #the two data points per frame\n",
        "  count = 0\n",
        "  dimensions = np.shape(accelerometer_data)\n",
        "\n",
        "  for row in range(0,dimensions[0]-1,2):\n",
        "    avg_array = np.sum(accelerometer_data[row:row+2,:],axis=0) / 2      \n",
        "    temp_array[count] = avg_array\n",
        "    count+=1\n",
        "  accelerometer_data = temp_array\n",
        "\n",
        "  #print(accelerometer_data[1][1])\n",
        "  return accelerometer_data"
      ],
      "metadata": {
        "id": "3sVC5dxDiB4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_vicon_data(total_data_sheet):\n",
        "  vicon_data = total_data_sheet[54006:,2:119]\n",
        "  return vicon_data"
      ],
      "metadata": {
        "id": "xSCkammAkR95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_emg_data(total_data_sheet):\n",
        "    #emg data contains ten data points per frame\n",
        "    delsys_emg_data = total_data_sheet[4:33744,2:18]\n",
        "    \n",
        "    #print(delsys_emg_data)\n",
        "    \n",
        "    temp_array = np.zeros(shape=(np.shape(delsys_emg_data)[0]//20, 16))   \n",
        "    #print(np.sum(delsys_emg_data[0:20,:],axis=0) / 20)\n",
        "    count = 0\n",
        "    dimensions = np.shape(delsys_emg_data)\n",
        "    #goes through all of the accelerometer data and finds the average of each of\n",
        "    #the ten data points per frame\n",
        "    for row in range(0,dimensions[0]-1,20):\n",
        "        avg_array = np.sum(delsys_emg_data[row:row+20,:],axis=0) / 20      \n",
        "        temp_array[count] = avg_array\n",
        "        count+=1\n",
        "   \n",
        "    delsys_emg_data = temp_array\n",
        "    \n",
        "    return delsys_emg_data"
      ],
      "metadata": {
        "id": "Lu33ltFzrSoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_emg_headers(total_data_sheet):\n",
        "\n",
        "  emg_headers = total_data_sheet[2,2:18]\n",
        "\n",
        "  return emg_headers"
      ],
      "metadata": {
        "id": "M7tx3Qvvqr9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_accelerometer_headers(total_data_sheet):\n",
        "\n",
        "  accelerometer_headers = total_data_sheet[50624,2:50]\n",
        "\n",
        "  return accelerometer_headers\n"
      ],
      "metadata": {
        "id": "VtZXNS84CgYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_vicon_dictionary(total_data_sheet):\n",
        "\n",
        "  vicon_data = compile_vicon_data(total_data_sheet)\n",
        "\n",
        "  column = 0\n",
        "  coordinate_count = 0\n",
        "  sub_headers = {}\n",
        "  vicon_headers = [\"LFHD\",\"RFHD\",\"LBDH\",\"RBHD\",\"C7\",\"T10\",\"CLAV\",\"STRN\",\"RBAK\",\"LSHO\",\"LUPA\",\"LELB\",\"LFRM\",\"LWRA\",\"LWRB\",\"LFIN\",\"RSHO\",\"RUPA\",\"RELB\",\"RFRM\",\"RWRA\",\"RWRB\",\"RFIN\",\"LASI\",\"RASI\",\"LPSI\",\"RPSI\",\"LTHI\",\"LKNE\",\"LTIB\",\"LANK\",\"LHEE\",\"LTOE\",\"RTHI\",\"RKNE\",\"RTIB\",\"RANK\",\"RHEE\",\"RTOE\"]\n",
        "  vicon_dictionary = {}\n",
        "\n",
        "  for header in vicon_headers:\n",
        "    marker = {}\n",
        "    for coordinate_count in range(0,3):\n",
        "      if coordinate_count == 0:\n",
        "        marker['X'] = vicon_data[:,column]\n",
        "        column+=1\n",
        "      elif coordinate_count == 1:\n",
        "        marker['Y'] = vicon_data[:,column]\n",
        "        column+=1\n",
        "      elif coordinate_count == 2:\n",
        "        marker['Z'] = vicon_data[:,column]\n",
        "        column+=1\n",
        "    \n",
        "    vicon_dictionary[header] = marker\n",
        "  print(vicon_dictionary['LFHD'])\n",
        "  return vicon_dictionary\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a4p2W9rrCtLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parse_vicon_dictionary(total_data_sheet)"
      ],
      "metadata": {
        "id": "X8dBRP4u7oHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_accelerometer_dictionary(total_data_sheet):\n",
        "  accelerometer_headers = [\"ACC1\",\"ACC2\",\"ACC3\",\"ACC4\",\"ACC5\",\"ACC6\",\"ACC7\",\"ACC8\",\"ACC9\",\"ACC10\",\"ACC11\",\"ACC12\",\"ACC13\",\"ACC14\",\"ACC15\",\"ACC16\"]\n",
        "  accelerometer_data = compile_accelerometer_data(total_data_sheet)\n",
        "\n",
        "  accelerometer_dictionary = {}\n",
        "  column = 0\n",
        "  for header in accelerometer_headers:\n",
        "    marker = {}\n",
        "    for coordinate_count in range(0,3):\n",
        "      if coordinate_count == 0:\n",
        "        marker['X'] = accelerometer_data[:,column]\n",
        "        column+=1\n",
        "      elif coordinate_count == 1:\n",
        "        marker['Y'] = accelerometer_data[:,column]\n",
        "        column+=1\n",
        "      elif coordinate_count == 2:\n",
        "        marker['Z'] = accelerometer_data[:,column]\n",
        "        column+=1\n",
        "    \n",
        "    accelerometer_dictionary[header] = marker\n",
        "  print(accelerometer_dictionary['ACC1'])"
      ],
      "metadata": {
        "id": "Lhsp3zzpGeXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parse_accelerometer_dictionary(total_data_sheet)\n"
      ],
      "metadata": {
        "id": "Zzkmg4gdJk9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_emg_dictionary(total_data_sheet):\n",
        "    emg_data = compile_emg_data(total_data_sheet)\n",
        "    emg_headers = parse_emg_headers(total_data_sheet)\n",
        "    count = 0\n",
        "    emg_dictionary = {}\n",
        "    for headers in emg_headers:\n",
        "        emg_dictionary[headers] = emg_data[:, count]\n",
        "        count += 1\n",
        "    #print(emg_dict.keys())\n",
        "    #print(emg_dict['EMG1'])\n",
        "\n",
        "    return emg_dictionary"
      ],
      "metadata": {
        "id": "qk-qy4hRqMFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_vicon_to_dictionary(total_data_sheet):\n",
        "  vicon_data = compile_vicon_data(total_data_sheet)\n",
        "  vicon_headers = parse_vicon_dictionary(total_data_sheet)\n",
        "  count = 0 \n",
        "  vicon_dictionary = {}\n",
        "  for headers in vicon_headers:\n",
        "    vicon_dictionary[headers] = vicon_data[:, count]\n",
        "    count += 1\n",
        "  return vicon_dictionary"
      ],
      "metadata": {
        "id": "zrnKicmD3J6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emg_data = compile_emg_data(total_data_sheet)\n",
        "emg_headers = parse_emg_headers(total_data_sheet)\n",
        "emg_dict = parse_emg_dictionary(emg_data,emg_headers)"
      ],
      "metadata": {
        "id": "MZC1yzGoEZ5-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a25ae6f-8209-4458-f93b-6c64699a7626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-d844c6be2102>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0memg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_emg_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_data_sheet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0memg_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_emg_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_data_sheet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0memg_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_emg_dictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memg_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0memg_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: parse_emg_dictionary() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# create dictionaries of consecutive toe minima to define toe-off points in gait cycle\n",
        "def find_toe_minima(vicon_dictionary):\n",
        "    LTOE_dict = vicon_dictionary['LTOE']\n",
        "    RTOE_dict = vicon_dictionary['RTOE']\n",
        "\n",
        "    # find minima (using z-coordinates) of each marker\n",
        "    LTOE_minima = signal.argrelmin(LTOE_dict['Z'], order=20)\n",
        "    RTOE_minima = signal.argrelmin(RTOE_dict['Z'], order=20)\n",
        "\n",
        "    # argrelmin output is tuple, create array of frames at which minima occur\n",
        "    LTOE_minima = LTOE_minima[0]\n",
        "    RTOE_minima = RTOE_minima[0]\n",
        "\n",
        "    # create dictionaries of minima for each marker, with frames as keys\n",
        "    L_mindict = {}\n",
        "    R_mindict = {}\n",
        "\n",
        "    # add minima to dictionaries\n",
        "    for frame in LTOE_minima:\n",
        "        L_mindict[frame] = LTOE_dict[frame]\n",
        "    for frame in RTOE_minima:\n",
        "        R_mindict[frame] = RTOE_dict[frame]\n",
        "\n",
        "    return LTOE_minima, RTOE_minima"
      ],
      "metadata": {
        "id": "ynbODIdtXQFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wire Frame and read connections"
      ],
      "metadata": {
        "id": "iyV1XvCtt_am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#n corresponds to the frame you chose ... FIX THIS FROM BEING A GLOBAL VARIABLE!!! \n",
        "# list of connections FROM, TO for the wireframe model\n",
        "\n",
        "\n",
        "def connect_coord(marker_1, marker_2, vicon_dictionary):\n",
        "    segment = [\n",
        "        [vicon_dictionary[marker_1][n, 0], vicon_dictionary[marker_2][n, 0]], #n corresponds to the frame you chose \n",
        "        [vicon_dictionary[marker_1][n, 1], vicon_dictionary[marker_2][n, 1]],\n",
        "        [vicon_dictionary[marker_1][n, 2], vicon_dictionary[marker_2][n, 2]], \n",
        "    ]\n",
        "    \n",
        "    return segment\n",
        "\n",
        "def build_model(vicon_dictionary):\n",
        "    connections = [\n",
        "      # head\n",
        "      ('RFHD', 'LFHD'),\n",
        "      ('LFHD', 'LBHD'),\n",
        "      ('LBHD', 'RBHD'),\n",
        "      ('RBHD', 'RFHD'),\n",
        "      # upper body/trunk\n",
        "      ('RSHO', 'CLAV'),\n",
        "      ('CLAV', 'LSHO'),\n",
        "      ('RSHO', 'LSHO'),\n",
        "      ('CLAV', 'C7'),\n",
        "      ('CLAV', 'STRN'),\n",
        "      ('C7', 'T10'),\n",
        "      ('STRN', 'T10'),\n",
        "      # upper limbs\n",
        "      ('RSHO', 'RUPA'),\n",
        "      ('RUPA', 'RELB'),\n",
        "      ('RELB', 'RFRM'),\n",
        "      ('RFRM', 'RWRA'),\n",
        "      ('RELB', 'RWRB'),\n",
        "      ('RWRA', 'RWRB'),\n",
        "      ('RWRA', 'RFIN'),\n",
        "      ('RWRB', 'RFIN'),\n",
        "      ('LSHO', 'LUPA'),\n",
        "      ('LUPA', 'LELB'),\n",
        "      ('LELB', 'LFRM'),\n",
        "      ('LFRM', 'LWRA'),\n",
        "      ('LELB', 'LWRB'),\n",
        "      ('LWRA', 'LWRB'),\n",
        "      ('LWRA', 'LFIN'),\n",
        "      ('LWRB', 'LFIN'),\n",
        "      # pelvis/hip\n",
        "      ('LASI', 'RASI'),\n",
        "      ('RASI', 'RPSI'),\n",
        "      ('RPSI', 'LPSI'),\n",
        "      ('LPSI', 'LASI'),\n",
        "      # lower limbs\n",
        "      ('RASI', 'RTHI'),\n",
        "      ('RPSI', 'RTHI'),\n",
        "      ('RASI', 'RKNE'),\n",
        "      ('RPSI', 'RKNE'),\n",
        "      ('RTHI', 'RKNE'),\n",
        "      ('RKNE', 'RTIB'),\n",
        "      ('RTIB', 'RANK'),\n",
        "      ('RHEE', 'RANK'),\n",
        "      ('RKNE', 'RANK'),\n",
        "      ('RANK', 'RTOE'),\n",
        "      ('RHEE', 'RTOE'),\n",
        "      ('LASI', 'LTHI'),\n",
        "      ('LPSI', 'LTHI'),\n",
        "      ('LASI', 'LKNE'),\n",
        "      ('LPSI', 'LKNE'),\n",
        "      ('LTHI', 'LKNE'),\n",
        "      ('LKNE', 'LTIB'),\n",
        "      ('LTIB', 'LANK'),\n",
        "      ('LHEE', 'LANK'),\n",
        "      ('LKNE', 'LANK'),\n",
        "      ('LANK', 'LTOE'),\n",
        "      ('LHEE', 'LTOE')\n",
        "    ]\n",
        "    # create list of segments, each connecting 2 markers\n",
        "    segments = []\n",
        "\n",
        "    for m1, m2 in connections:\n",
        "        segment = connect_coord(m1, m2, vicon_dictionary)\n",
        "        segments.append(segment)\n",
        "\n",
        "    return segments\n",
        "\n",
        "def plot_model(vicon_dict, n):\n",
        "\n",
        "    fig = pyplot.figure()\n",
        "    ax = {\n",
        "        'vicon': fig.add_subplot(1, 1, 1, projection='3d')\n",
        "    } \n",
        "\n",
        "    # iterate through markers and plot individual coordinates\n",
        "    for marker in markers:\n",
        "        x, y, z = vicon_dictionary[marker][n, :]\n",
        "        ax['vicon'].plot(x, y, z, marker='o', ms=3., markerfacecolor='k', color='k')\n",
        "    \n",
        "    # iterate through line segments list and plot connections\n",
        "    for segment in segments:\n",
        "        ax['vicon'].plot(segment[0], segment[1], segment[2], c='blue')\n",
        "    \n",
        "    # fix aspect ratio\n",
        "    ax['vicon'].set_aspect('equal')\n",
        "\n",
        "    # title figure\n",
        "    ax['vicon'].set_title('youngbin_vicon: frame ' + str(n))\n",
        "\n",
        "    # add axis labels\n",
        "    ax['vicon'].set_xlabel('x (mm)')\n",
        "    ax['vicon'].set_ylabel('y (mm)')\n",
        "    ax['vicon'].set_zlabel('z (mm)')\n",
        "\n",
        "    pyplot.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Z4KkOEKCuDUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find steps using gait cycle function"
      ],
      "metadata": {
        "id": "j-fuPAzQbrPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_heel_minima(vicon_dictionary):\n",
        "    LHEE_dict = vicon_dictionary['LHEE']\n",
        "    RHEE_dict = vicon_dictionary['RHEE']\n",
        "\n",
        "    # find minima (using z-coordinates) of each marker\n",
        "    LHEE_minima = signal.argrelmin(LHEE_dict['Z'], order=20)  #looking for order of z coordinates. The higher the order, the less minima it finds in that location \n",
        "    RHEE_minima = signal.argrelmin(RHEE_dict['Z'], order=20)\n",
        "\n",
        "    # argrelmin output is tuple, create array of frames at which minima occur\n",
        "    LHEE_minima = LHEE_minima[0] #describes the frames of the minima (when they occur)\n",
        "    RHEE_minima = RHEE_minima[0]\n",
        "\n",
        "    return LHEE_minima, RHEE_minima\n",
        "\n",
        "def find_toe_minima(vicon_dictionary):\n",
        "    LTOE_dict = vicon_dictionary['LTOE']\n",
        "    RTOE_dict = vicon_dictionary['RTOE']\n",
        "\n",
        "    # find minima (using z-coordinates) of each marker\n",
        "    LTOE_minima = signal.argrelmin(LTOE_dict['Z'], order=20)\n",
        "    RTOE_minima = signal.argrelmin(RTOE_dict['Z'], order=20)\n",
        "\n",
        "    # argrelmin output is tuple, create array of frames at which minima occur\n",
        "    LTOE_minima = LTOE_minima[0]\n",
        "    RTOE_minima = RTOE_minima[0]\n",
        "\n",
        "    return LTOE_minima, RTOE_minima\n",
        "    print(LTOE_minima)\n"
      ],
      "metadata": {
        "id": "mpe1vurHZkZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counting steps: Combine lists (heel and toe) Left (-1) and Right (+1)\n"
      ],
      "metadata": {
        "id": "UrGkua0ZcWiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_lists(list1, list2):\n",
        "    combined_dict = {}\n",
        "\n",
        "    # -1 is assigned to left marker\n",
        "    for i in list1:\n",
        "        combined_dict[i] = -1\n",
        "\n",
        "    # +1 is assigned to right marker\n",
        "    for i in list2:\n",
        "        combined_dict[i] = 1\n",
        "\n",
        "    # sort dictionary of step times into chronological order\n",
        "    combined_dict = sorted(combined_dict.items())\n",
        "    sorted_dict = sorted(combined_dict)\n",
        "    combined_dict = dict(sorted_dict)\n",
        "    # print(combined_dict.items())\n",
        "\n",
        "    return combined_dict\n",
        "\n",
        "def scan_dict(combined_dict): #looks for zeroes to determine pairing... if not zero, break current list \n",
        "    filtered_pairs = []\n",
        "    filtered_pairs_temp = []\n",
        "    keys_list = []\n",
        "\n",
        "    for i in combined_dict.keys():\n",
        "      keys_list.append(i)\n",
        "    print('keys list', keys_list)     \n",
        "# iterate through combined dictionary of L and R minima\n",
        "# check if consecutive values are from opposite feet (-1 + 1 = 0)\n",
        "# if sum of values is not 0, consecutive values are from the same foot\n",
        "# print(keys_list)\n",
        "    for i in range(0, len(keys_list) - 1):\n",
        "      current_key = keys_list[i]\n",
        "      next_key = keys_list[i + 1]\n",
        "      sum = combined_dict[current_key] + combined_dict[next_key]\n",
        "    # print(sum)\n",
        "\n",
        "      if sum == 0:\n",
        "        filtered_pairs_temp.append((current_key, next_key))\n",
        "      # print(current_key,',', next_key)\n",
        "      else:\n",
        "          if len(filtered_pairs_temp) > 0:\n",
        "              filtered_pairs.append(filtered_pairs_temp)\n",
        "          filtered_pairs_temp = []\n",
        "\n",
        "# print(filtered_pairs)\n",
        "    return filtered_pairs #list of lists of pairs (applicable to both heel and toe markers )\n",
        "\n",
        "def find_filtered_frames(filtered_pairs, combined_dict, vicon_dict, datatype=''):\n",
        "    L_combined_list = []\n",
        "    R_combined_list = []\n",
        "    L_combined_temp = []\n",
        "    R_combined_temp = []\n",
        "\n",
        "    for item in filtered_pairs:\n",
        "        if len(item) > 0:\n",
        "            for i in range(0, len(item)):\n",
        "                f1, f2 = item[i]\n",
        "                if combined_dict[f1] == -1 and f1 not in L_combined_temp:\n",
        "                    L_combined_temp.append(f1)\n",
        "                if combined_dict[f1] == 1 and f1 not in R_combined_temp:\n",
        "                    R_combined_temp.append(f1)\n",
        "                if combined_dict[f2] == -1 and f2 not in L_combined_temp:\n",
        "                    L_combined_temp.append(f2)\n",
        "                if combined_dict[f2] == 1 and f2 not in R_combined_temp:\n",
        "                    R_combined_temp.append(f2)\n",
        "\n",
        "            L_combined_list.append(L_combined_temp)\n",
        "            R_combined_list.append(R_combined_temp)\n",
        "\n",
        "        L_combined_temp = []\n",
        "        R_combined_temp = []\n",
        "\n",
        "    # print(L_combined_list)\n",
        "    # print(R_combined_list)\n",
        "\n",
        "    L_gradients = np.gradient(vicon_dictionary['LTOE']['Z'])\n",
        "    R_gradients = np.gradient(vicon_dictionary['RTOE']['Z'])\n",
        "    L_double_gradients = np.gradient(L_gradients)\n",
        "    R_double_gradients = np.gradient(R_gradients)\n",
        "\n",
        "    # print(L_double_gradients)... not the exact frame of toe off but very close\n",
        "    #double gradient refers to the second derivativeâ€“the maxes that represent toe off points. \n",
        "    #This is how you find the absolute minima for a given cycle (to differentiate from other toe minima in the area) (in numpy, the function is gradient) \n",
        "    L_double_grad_maxes = signal.argrelmax(L_double_gradients, order=20)\n",
        "    L_double_grad_maxes = L_double_grad_maxes[0]\n",
        "    R_double_grad_maxes = signal.argrelmax(R_double_gradients, order=20)\n",
        "    R_double_grad_maxes = R_double_grad_maxes[0]  \n",
        "  \n",
        "    # print(L_double_grad_maxes)\n",
        "\n",
        "    if datatype == 'toe':\n",
        "        LTOE_zmin_frames = []\n",
        "        RTOE_zmin_frames = []\n",
        "        L_final_frames = []\n",
        "        R_final_frames = []\n",
        "        L_master_list = []\n",
        "        R_master_list = []\n",
        "\n",
        "        for i in range(0, len(L_combined_list)):\n",
        "            current_list = L_combined_list[i]\n",
        "            for frame in current_list:\n",
        "                LTOE_zmin_frames.append(frame)\n",
        "        for i in LTOE_zmin_frames:\n",
        "            if i in L_double_grad_maxes:\n",
        "                L_final_frames.append(i)\n",
        "            elif i + 1 in L_double_grad_maxes:\n",
        "                L_final_frames.append(i)\n",
        "            elif i - 1 in L_double_grad_maxes:\n",
        "                L_final_frames.append(i)\n",
        "            elif i + 2 in L_double_grad_maxes:\n",
        "                L_final_frames.append(i)\n",
        "            elif i - 2 in L_double_grad_maxes:\n",
        "                L_final_frames.append(i)\n",
        "\n",
        "        for i in range(0, len(R_combined_list)):\n",
        "            current_list = R_combined_list[i]\n",
        "            for frame in current_list:\n",
        "                LTOE_zmin_frames.append(frame)\n",
        "        for i in LTOE_zmin_frames:\n",
        "            if i in R_double_grad_maxes:\n",
        "                R_final_frames.append(i)\n",
        "            elif i + 1 in R_double_grad_maxes:\n",
        "                R_final_frames.append(i)\n",
        "            elif i - 1 in R_double_grad_maxes:\n",
        "                R_final_frames.append(i)\n",
        "            elif i + 2 in R_double_grad_maxes:\n",
        "                R_final_frames.append(i)\n",
        "            elif i - 2 in R_double_grad_maxes:\n",
        "                R_final_frames.append(i)\n",
        "        \n",
        "        # print(L_final_frames)\n",
        "        L_sublist_dict = {}\n",
        "        for i in range(0, len(L_final_frames)):\n",
        "            for m in range(0, len(L_combined_list)):\n",
        "                current_list = L_combined_list[m]\n",
        "                if L_final_frames[i] in current_list:\n",
        "                    if m not in L_sublist_dict.keys():\n",
        "                        L_sublist_dict[m] = []\n",
        "                    L_sublist_dict[m].append(L_final_frames[i])\n",
        "                    break\n",
        "        # print(sublist_dict)\n",
        "        for key in list(sorted(L_sublist_dict.keys())):\n",
        "            L_master_list.append(L_sublist_dict[key])\n",
        "        # print(L_master_list)\n",
        "\n",
        "        R_sublist_dict = {}\n",
        "        for i in range(0, len(R_final_frames)):\n",
        "            for m in range(0, len(R_combined_list)):\n",
        "                current_list = R_combined_list[m]\n",
        "                if R_final_frames[i] in current_list:\n",
        "                    if m not in R_sublist_dict.keys():\n",
        "                        R_sublist_dict[m] = []\n",
        "                    R_sublist_dict[m].append(R_final_frames[i])\n",
        "                    break\n",
        "        # print(sublist_dict)\n",
        "        for key in list(sorted(R_sublist_dict.keys())):\n",
        "            R_master_list.append(R_sublist_dict[key])\n",
        "\n",
        "        L_combined_list = L_master_list\n",
        "        R_combined_list = R_master_list\n",
        "\n",
        "    print(L_combined_list)\n",
        "    # print(R_combined_list)\n",
        "    \n",
        "    return L_combined_list, R_combined_list\n"
      ],
      "metadata": {
        "id": "eGJJ_2Arcbzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vicon_dictionary = parse_vicon_dictionary(total_data_sheet)\n",
        "LHEE_minima, RHEE_minima = find_heel_minima(vicon_dictionary)\n",
        "print(LHEE_minima)\n",
        "#these are the frames for which the left heel is at a minima \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBnnAgU8gZJp",
        "outputId": "f7a87b00-4d2c-441d-bb60-aa104cc0ecf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'X': array([1179.567627, 1180.465088, 1183.190186, ..., 1100.72937,\n",
            "       1099.951294, 1099.004639], dtype=object), 'Y': array([980.660767, 979.854248, 980.890991, ..., 1129.947754, 1129.679565,\n",
            "       1131.239746], dtype=object), 'Z': array([1644.505615, 1643.941162, 1643.405151, ..., 1670.339478,\n",
            "       1670.677612, 1671.902222], dtype=object)}\n",
            "[   3  127  223  357  486  592  709  848  983 1009 1097 1158 1215 1361\n",
            " 1652 1684]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/signal/_peak_finding.py:75: RuntimeWarning: invalid value encountered in less\n",
            "  results &= comparator(main, plus)\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/signal/_peak_finding.py:76: RuntimeWarning: invalid value encountered in less\n",
            "  results &= comparator(main, minus)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vicon_dictionary = parse_vicon_dictionary(total_data_sheet)\n",
        "LTOE_minima, RTOE_minima = find_toe_minima(vicon_dictionary)\n",
        "heel_combined_dict = combine_lists(LHEE_minima, RHEE_minima)\n",
        "toe_combined_dict = combine_lists(LTOE_minima, RTOE_minima)\n",
        "heel_filtered_pairs = scan_dict(heel_combined_dict)\n",
        "toe_filtered_pairs = scan_dict(toe_combined_dict)\n",
        "LHEE_combined_list, RHEE_combined_list = find_filtered_frames(heel_filtered_pairs, heel_combined_dict, vicon_dictionary)\n",
        "LTOE_combined_list, RTOE_combined_list = find_filtered_frames(toe_filtered_pairs, toe_combined_dict, vicon_dictionary, 'toe')\n",
        "print(toe_filtered_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KP_5o-ZIjjVq",
        "outputId": "c4366cbd-2c84-4bdc-b439-e134055666de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'X': array([1179.567627, 1180.465088, 1183.190186, ..., 1100.72937,\n",
            "       1099.951294, 1099.004639], dtype=object), 'Y': array([980.660767, 979.854248, 980.890991, ..., 1129.947754, 1129.679565,\n",
            "       1131.239746], dtype=object), 'Z': array([1644.505615, 1643.941162, 1643.405151, ..., 1670.339478,\n",
            "       1670.677612, 1671.902222], dtype=object)}\n",
            "keys list [3, 71, 127, 182, 223, 291, 357, 425, 486, 573, 592, 623, 709, 780, 848, 925, 983, 1009, 1080, 1097, 1129, 1158, 1215, 1292, 1361, 1434, 1555, 1652, 1679, 1684]\n",
            "keys list [7, 59, 177, 242, 311, 375, 446, 504, 505, 538, 560, 585, 656, 731, 800, 869, 947, 1015, 1037, 1048, 1069, 1130, 1175, 1237, 1313, 1384, 1525, 1628, 1638, 1673]\n",
            "[[3, 127, 223, 357, 486, 592, 709, 848, 983], [1009, 1097, 1158], [1215, 1361]]\n",
            "[[177, 311, 446, 505, 560, 656, 800, 947], [1175, 1313]]\n",
            "[[(7, 59)], [(177, 242), (242, 311), (311, 375), (375, 446), (446, 504), (504, 505), (505, 538), (538, 560), (560, 585), (585, 656), (656, 731), (731, 800), (800, 869), (869, 947), (947, 1015)], [(1037, 1048), (1048, 1069), (1069, 1130)], [(1175, 1237), (1237, 1313), (1313, 1384)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Double Support Time, a feature of PD patients"
      ],
      "metadata": {
        "id": "OIWJ1iIKqYss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_cycles(LHEE_combined_list, RHEE_combined_list, LTOE_combined_list, RTOE_combined_list):\n",
        "    L_gait_boundaries = []\n",
        "    R_gait_boundaries = []\n",
        "\n",
        "    # make a list of ranges (also lists) marking the boundaries of each full cycle\n",
        "    # for LHEE strikes\n",
        "    # this will not combine two LHEE heel strikes from separate lists within combined_list\n",
        "    # no connections across missing/removed steps will be made\n",
        "    for i in range(0, len(LHEE_combined_list) - 1):\n",
        "        current_list = LHEE_combined_list[i]\n",
        "        if len(current_list) == 1:\n",
        "            continue\n",
        "        else:\n",
        "            for n in range(0, len(current_list) - 1):\n",
        "                hs_initial = current_list[n]\n",
        "                hs_next = current_list[n + 1]\n",
        "                L_gait_boundaries.append([hs_initial, hs_next])\n",
        "    # print(L_gait_boundaries)\n",
        "    \n",
        "    # for RHEE strikes\n",
        "    for i in range(0, len(RHEE_combined_list) - 1):\n",
        "        current_list = RHEE_combined_list[i]\n",
        "        if len(current_list) == 1:\n",
        "            continue\n",
        "        else:\n",
        "            for n in range(0, len(current_list) - 1):\n",
        "                hs_initial = current_list[n]\n",
        "                hs_next = current_list[n + 1]\n",
        "                R_gait_boundaries.append([hs_initial, hs_next])           \n",
        "    # print(R_gait_boundaries)\n",
        "\n",
        "    # list of (L IC 1, R IC 1, L IC2) cycles\n",
        "    cycle_bounds = []\n",
        "\n",
        "    # check for right heel strike frames that come in between boundaries\n",
        "    # add between the initial and subsequent left heel strike frames\n",
        "    for i in range(0, len(L_gait_boundaries)):\n",
        "        current_L_cycle = L_gait_boundaries[i]\n",
        "        L_bound_1 = current_L_cycle[0]\n",
        "        L_bound_2 = current_L_cycle[1]\n",
        "\n",
        "        for n in range(0, len(R_gait_boundaries)):\n",
        "            test_R_cycle = R_gait_boundaries[n]\n",
        "            R_bound_1 = test_R_cycle[0]\n",
        "            R_bound_2 = test_R_cycle[1]\n",
        "\n",
        "            if L_bound_1 < R_bound_1 < L_bound_2:\n",
        "                cycle_bounds.append((L_bound_1, R_bound_1, L_bound_2))\n",
        "\n",
        "            if L_bound_1 < R_bound_2 < L_bound_2:\n",
        "                cycle_bounds.append((L_bound_1, R_bound_2, L_bound_2))\n",
        "\n",
        "    \n",
        "    cycle_bounds = list(set(cycle_bounds))\n",
        "    cycle_bounds = list(sorted(cycle_bounds))\n",
        "\n",
        "    # make each gait cycle its own dictionary\n",
        "    # the keys of each dictionary are gait events (heel strike, toe-off)\n",
        "    # exact keys (for full dict): 'LHS1', 'RTO', 'RHS', 'LTO', LHS2'\n",
        "    cycles = []\n",
        "    cycles_dict = {}\n",
        "    for i in range(0, len(cycle_bounds)):\n",
        "        cycles_dict['LHS1'] = cycle_bounds[i][0]\n",
        "        cycles_dict['RHS'] = cycle_bounds[i][1]\n",
        "        cycles_dict['LHS2'] = cycle_bounds[i][2]\n",
        "        cycles.append(cycles_dict)\n",
        "        cycles_dict = {}\n",
        "  \n",
        "\n",
        "    return cycles\n",
        "\n",
        "# include toe-off events in the dictionaries if their values are\n",
        "# between their surrounding heel strike events\n",
        "def toe_events(cycles, LTOE_combined_list, RTOE_combined_list):\n",
        "    L_toe_offs = []\n",
        "    R_toe_offs = []\n",
        "    gait_cycles = []\n",
        "\n",
        "    if len(LTOE_combined_list) == 1:\n",
        "        current_list = LTOE_combined_list[0]\n",
        "        if len(current_list) > 1:\n",
        "            for n in range(0, len(current_list) - 1):\n",
        "                to_initial = current_list[n]\n",
        "                to_next = current_list[n + 1]\n",
        "                L_toe_offs.append([to_initial, to_next])\n",
        "    else:\n",
        "        for i in range(0, len(LTOE_combined_list)):\n",
        "            current_list = LTOE_combined_list[i]\n",
        "            if len(current_list) == 1:\n",
        "                continue\n",
        "            else:\n",
        "                for n in range(0, len(current_list) - 1):\n",
        "                    to_initial = current_list[n]\n",
        "                    to_next = current_list[n + 1]\n",
        "                    L_toe_offs.append([to_initial, to_next])\n",
        "\n",
        "    if len(RTOE_combined_list) == 1:\n",
        "        current_list = RTOE_combined_list[0]\n",
        "        if len(current_list) > 1:\n",
        "            for n in range(0, len(current_list) - 1):\n",
        "                to_initial = current_list[n]\n",
        "                to_next = current_list[n + 1]\n",
        "                R_toe_offs.append([to_initial, to_next])\n",
        "    else:\n",
        "        for i in range(0, len(RTOE_combined_list)):\n",
        "            current_list = RTOE_combined_list[i]\n",
        "            if len(current_list) > 1:\n",
        "                for n in range(0, len(current_list) - 1):\n",
        "                    to_initial = current_list[n]\n",
        "                    to_next = current_list[n + 1]\n",
        "                    R_toe_offs.append([to_initial, to_next])\n",
        "\n",
        "    # print(R_toe_offs)\n",
        "\n",
        "    for i in range(0, len(cycles)):\n",
        "        current_cycle = cycles[i]\n",
        "        # insert right TO values between left initial and right HS\n",
        "        for n in range(0, len(R_toe_offs)):\n",
        "            RTO1 = R_toe_offs[n][0]\n",
        "            RTO2 = R_toe_offs[n][1]\n",
        "\n",
        "            if current_cycle['LHS1'] < RTO1 < current_cycle['RHS']:\n",
        "                current_cycle['RTO'] = RTO1\n",
        "            if current_cycle['LHS1'] < RTO2 < current_cycle['RHS']:\n",
        "                current_cycle['RTO'] = RTO2\n",
        "\n",
        "        # insert left TO values into cycles\n",
        "        for m in range(0, len(L_toe_offs)):\n",
        "            LTO1 = L_toe_offs[m][0]\n",
        "            LTO2 = L_toe_offs[m][1]\n",
        "\n",
        "            if current_cycle['RHS'] < LTO1 < current_cycle['LHS2']:\n",
        "                current_cycle['LTO'] = LTO1\n",
        "            if current_cycle['RHS'] < LTO2 < current_cycle['LHS2']:\n",
        "                current_cycle['LTO'] = LTO2\n",
        "        \n",
        "  \n",
        "        gait_cycles.append(current_cycle)\n",
        "\n",
        "    print(gait_cycles)\n",
        "\n",
        "    return gait_cycles\n",
        "\n",
        "# only include gait cycles with all HS and TO events in calculations\n",
        "def filter_gc(gait_cycles):\n",
        "    full_gait_cycles = []\n",
        "    for i in range(0, len(gait_cycles)):\n",
        "        if len(gait_cycles[i].keys()) == 5:\n",
        "            full_gait_cycles.append(gait_cycles[i])\n",
        "    \n",
        "    print(full_gait_cycles)\n",
        "\n",
        "    return full_gait_cycles\n",
        "\n",
        "# calculates how long each gait cycle is (in frames)\n",
        "def gait_cycle_times(full_gait_cycles):\n",
        "    cycle_times = []\n",
        "\n",
        "    for cycle in full_gait_cycles:\n",
        "        cycle_time = cycle['LHS2'] - cycle['LHS1']\n",
        "        cycle_times.append(cycle_time)\n",
        "    \n",
        "    # uncomment below to define gait cycles starting with R foot heel strike\n",
        "    # for cycle in cycles:\n",
        "    #     cycle_time = cycle['RHS2'] - cycle['RHS1']\n",
        "    #     cycle_times.append(cycle_time)\n",
        "\n",
        "    cycle_times = np.array(cycle_times)\n",
        "    # print(cycle_times)\n",
        "\n",
        "    cycle_times_clean = cd.remove_outliers(cycle_times)\n",
        "    # print(cycle_times_clean)\n",
        "    # print(np.average(cycle_times_clean))\n",
        "\n",
        "    return cycle_times, cycle_times_clean\n",
        "\n",
        "def support_time(full_gait_cycles):\n",
        "    ds_times = []\n",
        "    ss_times_L = []\n",
        "    ss_times_R = []\n",
        "    \n",
        "    for i in range(0, len(full_gait_cycles)):\n",
        "        # calculate single support times for each leg\n",
        "        current_cycle = full_gait_cycles[i]\n",
        "        L_single = current_cycle['RHS'] - current_cycle['RTO']\n",
        "        R_single = current_cycle['LHS2'] - current_cycle['LTO']\n",
        "        # uncomment below if gait cycles start with RHS\n",
        "        # R_single = current_cycle['LHS'] - current_cycle['LTO']\n",
        "        # L_single = current_cycle['RHS2'] - current_cycle['RTO']\n",
        "        current_cycle['L_ss'] = L_single\n",
        "        current_cycle['R_ss'] = R_single\n",
        "\n",
        "        ss_times_L.append(L_single)\n",
        "        ss_times_R.append(R_single)\n",
        "\n",
        "        # calculate double support time for the cycle\n",
        "        double = (current_cycle['RTO'] - current_cycle['LHS1']) + (current_cycle['LTO'] - current_cycle['RHS'])\n",
        "        # double = (current_cycle['LTO'] - current_cycle['RHS1']) + (current_cycle['RTO'] - current_cycle['LHS'])\n",
        "        current_cycle['ds'] = double\n",
        "\n",
        "        ds_times.append(double)\n",
        "    \n",
        "    # add single and double support times into arrays\n",
        "    ss_times_L = np.array(ss_times_L)\n",
        "    ss_times_R = np.array(ss_times_R)\n",
        "    ds_times = np.array(ds_times)\n",
        "\n",
        "    return ss_times_L, ss_times_R, ds_times"
      ],
      "metadata": {
        "id": "MP4rLjs1qeRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cycles = separate_cycles(LHEE_combined_list, RHEE_combined_list, LTOE_combined_list, RTOE_combined_list)\n",
        "print(cycles)\n",
        "#print('LHEE', LHEE_combined_list)\n",
        "#print('RHEE', RHEE_combined_list)\n",
        "#print('LTOE', LTOE_combined_list)\n",
        "#print('RTOE', RTOE_combined_list)\n",
        "gait_cycles = toe_events(cycles, LTOE_combined_list, RTOE_combined_list)\n",
        "#print(gait_cycles)\n",
        "full_gait_cycles = filter_gc(gait_cycles)\n",
        "print('full gait cycles,' ,full_gait_cycles) #5 markers in each section "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6HXr4wZqsCu",
        "outputId": "8b6e7776-e8ef-470b-9cd4-fcac490b813e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'LHS1': 3, 'RHS': 71, 'LHS2': 127}, {'LHS1': 127, 'RHS': 182, 'LHS2': 223}, {'LHS1': 223, 'RHS': 291, 'LHS2': 357}, {'LHS1': 357, 'RHS': 425, 'LHS2': 486}, {'LHS1': 486, 'RHS': 573, 'LHS2': 592}, {'LHS1': 592, 'RHS': 623, 'LHS2': 709}, {'LHS1': 709, 'RHS': 780, 'LHS2': 848}, {'LHS1': 848, 'RHS': 925, 'LHS2': 983}, {'LHS1': 1009, 'RHS': 1080, 'LHS2': 1097}, {'LHS1': 1097, 'RHS': 1129, 'LHS2': 1158}]\n",
            "[{'LHS1': 3, 'RHS': 71, 'LHS2': 127}, {'LHS1': 127, 'RHS': 182, 'LHS2': 223}, {'LHS1': 223, 'RHS': 291, 'LHS2': 357, 'RTO': 242, 'LTO': 311}, {'LHS1': 357, 'RHS': 425, 'LHS2': 486, 'RTO': 375, 'LTO': 446}, {'LHS1': 486, 'RHS': 573, 'LHS2': 592}, {'LHS1': 592, 'RHS': 623, 'LHS2': 709, 'LTO': 656}, {'LHS1': 709, 'RHS': 780, 'LHS2': 848, 'RTO': 731, 'LTO': 800}, {'LHS1': 848, 'RHS': 925, 'LHS2': 983, 'RTO': 869, 'LTO': 947}, {'LHS1': 1009, 'RHS': 1080, 'LHS2': 1097, 'RTO': 1069}, {'LHS1': 1097, 'RHS': 1129, 'LHS2': 1158}]\n",
            "[{'LHS1': 223, 'RHS': 291, 'LHS2': 357, 'RTO': 242, 'LTO': 311}, {'LHS1': 357, 'RHS': 425, 'LHS2': 486, 'RTO': 375, 'LTO': 446}, {'LHS1': 709, 'RHS': 780, 'LHS2': 848, 'RTO': 731, 'LTO': 800}, {'LHS1': 848, 'RHS': 925, 'LHS2': 983, 'RTO': 869, 'LTO': 947}]\n",
            "full gait cycles, [{'LHS1': 223, 'RHS': 291, 'LHS2': 357, 'RTO': 242, 'LTO': 311}, {'LHS1': 357, 'RHS': 425, 'LHS2': 486, 'RTO': 375, 'LTO': 446}, {'LHS1': 709, 'RHS': 780, 'LHS2': 848, 'RTO': 731, 'LTO': 800}, {'LHS1': 848, 'RHS': 925, 'LHS2': 983, 'RTO': 869, 'LTO': 947}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Joint Angles (crediting [source](https://www.mdpi.com/1424-8220/22/19/7178) for equation )"
      ],
      "metadata": {
        "id": "D9-BB7OxyVbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Define a function to calculate the angle between two vectors\n",
        "#define what the angles are\n",
        "def calculate_angle(vector1, vector2):\n",
        "    dot_product = sum([vector1[i]*vector2[i] for i in range(len(vector1))])\n",
        "    vector1_length = math.sqrt(sum([v**2 for v in vector1]))\n",
        "    vector2_length = math.sqrt(sum([v**2 for v in vector2]))\n",
        "    cos_theta = dot_product / (vector1_length * vector2_length)\n",
        "    return math.acos(cos_theta)\n",
        "\n",
        "# Define the vectors constituting the angles\n",
        "vector_AB = [1, 0, 0]   # Vector from A to B\n",
        "vector_BC = [0, 1, 0]   # Vector from B to C\n",
        "vector_CD = [0, 0, 1]   # Vector from C to D\n",
        "vector_DE = [0, 1, 1]   # Vector from D to E\n",
        "vector_EF = [1, 0, 1]   # Vector from E to F\n",
        "vector_FG = [1, 1, 0]   # Vector from F to G\n",
        "\n",
        "# Calculate the angles (hip, knee, ankle joint)\n",
        "angle_ABC = calculate_angle(vector_AB, vector_BC)\n",
        "angle_CDE = calculate_angle(vector_CD, vector_DE)\n",
        "angle_EFG = calculate_angle(vector_EF, vector_FG)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Angle ABC: {math.degrees(angle_ABC)} degrees\")\n",
        "print(f\"Angle CDE: {math.degrees(angle_CDE)} degrees\")\n",
        "print(f\"Angle EFG: {math.degrees(angle_EFG)} degrees\")\n"
      ],
      "metadata": {
        "id": "ezYZ7peQyT9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c11233e6-948f-4baf-b17e-bf3abcd82a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Angle ABC: 90.0 degrees\n",
            "Angle CDE: 45.00000000000001 degrees\n",
            "Angle EFG: 60.00000000000001 degrees\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Box and Whisker Data Visualization for Hip and Knee angles (4 subplots swing, stance for each marker) [source](https://www.mdpi.com/1424-8220/22/19/7178) "
      ],
      "metadata": {
        "id": "ClbVUalI0-pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anvil.server.wait_forever()"
      ],
      "metadata": {
        "id": "PRbM0pIR1WxG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}